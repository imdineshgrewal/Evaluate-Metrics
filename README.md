# Evaluate-Metrics

Performance Evaluation
Performance evaluation plays a dominant role in the technique of predictive modelling. The performance of a predictive model is calculated and compared by choosing the right metrics. So, it is very crucial to choose the right metrics for a particular predictive model in order to get an accurate outcome. It is very important to evaluate proper predictive models because various kinds of data sets are going to be used for the same predictive model.

Common Metrics That Are Used To Evaluate Predictive Models
Area Under The ROC Curve (AUC-ROC): This is one of the popular metrics that has been used in the industry. The nature of this metric is independent of the change in the proportion of responders and that’s the biggest advantage of this metric. A model will be represented as a single point in the ROC plot where the class is an outcome.



###Confusion Matrix: 
This is an NXN matrix where N is called the number of classes being predicted. This metric is called an error matrix and it portrays a dominant role for prediction mainly in the issues of statistical categorization. It is a special table with dimensions of two namely the actual and predicted with an identical class.

 

Also Read  When It Comes To Python And R, We Don’t Need To Mind Our Language
###Concordant- Discordant Ratio: 
This model is used to describe the relationship between pairs of observations where the data are treated as ordinal. The method of calculating this ratio compares the classifications for two variables on the same two items.

###Cross-Validation: 
This is a resampling procedure and is important in any type of data modelling. This metric is used to compare and select a model for a given predictive modelling problem.

###Gain and Lift Chart: 
In this metric, both the charts are used to measure the effectiveness of a model and it deals to check the rank ordering of probabilities. This method follows like calculating the probability for each observation and then ranking them in decreasing order. After ranking, build deciles with each group and lastly, calculate the response rate at each decile.

###Kolmogorov Smirnov chart: 
The K-S chart measures the degree of separation between the positive and negative distributions of a model. In most classification models, the K-S gives values between 0 and 100, where the higher value is considered as the better model.

###Mean Square Error: 
If the data contains a huge number of outliers, then this metric is known to be a good one.

###Median Absolute Error: 
This metric represents the average of the absolute differences between the actual observation and the prediction.

###Percent Correction Classification: 
This metric measures the overall accuracy where every error has the same weight.

###Root Mean Squared Error: 
This is one of the popular metrics that is mainly used in regression problems. This metric assumes that the error is unbiased and follows a normal distribution.

